{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"15\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import Sequence\n",
    "from keras.layers import Dense, Activation, Input, Conv1D, MaxPooling1D, Reshape\n",
    "from keras.optimizers import Adam\n",
    "from keras import Model\n",
    "import numpy as np\n",
    "from seqdataloader.batchproducers.coordbased.core import Coordinates\n",
    "from seqdataloader.batchproducers.coordbased.coordstovals.fasta import PyfaidxCoordsToVals\n",
    "from pyfaidx import Fasta\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainGenerator(Sequence):\n",
    "    def __init__(self):\n",
    "        self.trainingfile = training_set\n",
    "        self.converter = PyfaidxCoordsToVals('GRCh38.p13.genome.fa')\n",
    "        self.batchsize = batchsize\n",
    "        self.steps_per_epoch = train_steps\n",
    "        self.total_epochs = num_epochs  # how many epochs to train for (you're using enough epochs when the loss stops going down)\n",
    "        self.get_coords()\n",
    "        self.on_epoch_end()\n",
    "    def __len__(self):  # required by Keras -- returns # of batches to expect\n",
    "        print('running __len__')\n",
    "        return self.steps_per_epoch\n",
    "    def get_coords(self):\n",
    "        print(\"running get_coords(\" + str(int(time.time() - start)) + \"sec)\")\n",
    "        with open(self.trainingfile) as trainf:\n",
    "            #self.labels = [int(line.split()[-6:]) for line in trainf]  # assumes last columns in file are the labels, and assumes 6 label columns\n",
    "            #coords_tmp = [line.split()[:3] for line in trainf]\n",
    "            #self.coords = [Coordinates(coord[0], int(coord[1]), int(coord[2])) for coord in coords_tmp]\n",
    "            self.labels = []\n",
    "            self.coords = []\n",
    "            for line in trainf:\n",
    "                temp = line.split()\n",
    "                tempList = [temp[0], int(temp[1]), int(temp[2]), float(temp[3]), float(temp[4]), \n",
    "                            float(temp[5]), float(temp[6]), int(temp[7]), int(temp[8])]\n",
    "                for ind in range(len(tempList)):\n",
    "                    if (ind < 3 or ind > 6):\n",
    "                        continue\n",
    "                    if (tempList[ind] > threshold):\n",
    "                        tempList[ind] = 1\n",
    "                    else:\n",
    "                        tempList[ind] = 0\n",
    "                    #tempList[ind] = int(tempList[ind])\n",
    "                self.labels.append(tempList[-6:-2]) #4 label columns\n",
    "                self.coords.append(Coordinates(tempList[0], tempList[1], tempList[2]))\n",
    "            #should I cast them as numpy arrays?\n",
    "    def __getitem__(self, batch_index):\n",
    "        #print(\"running __getitem__\")\n",
    "        ##print(\"running __getitem__(\" + str(int(time.time() - start)) + \"sec)\")\n",
    "        # get one-hot encoded sequences, using coordinates, for the next batch\n",
    "        seqs_onehot = self.converter(self.coords[batch_index * self.batchsize : (batch_index + 1) * self.batchsize])\n",
    "        # get labels for the next batch\n",
    "        labels = self.labels[batch_index * self.batchsize : (batch_index + 1) * self.batchsize]\n",
    "        \n",
    "        if (seqs_onehot.shape[0] == 0):\n",
    "            print(\"DEBUG: seqs_onehot.shape[0] == 0\")\n",
    "            print(\"batch_index: \" + str(batch_index))\n",
    "            print(\"self.batchsize: \" + str(self.batchsize))\n",
    "            print(\"self.coords[batch_index * self.batchsize : (batch_index + 1) * self.batchsize]\")\n",
    "            print(self.coords[batch_index * self.batchsize : (batch_index + 1) * self.batchsize])\n",
    "        \n",
    "        # sanity checks\n",
    "        assert seqs_onehot.shape[0] == np.array(labels).shape[0], (seqs_onehot.shape[0], np.array(labels).shape[0])\n",
    "        assert seqs_onehot.shape[0] == self.batchsize, (seqs_onehot.shape[0], self.batchsize)\n",
    "        return seqs_onehot, np.array(labels) #return all_seqs, np.array(self.labels)\n",
    "    def on_epoch_end(self):\n",
    "        # shuffle labels and coordinates (together) between epochs\n",
    "        #print(\"running on_epoch_end\")\n",
    "        print(\"running on_epoch_end(\" + str(int(time.time() - start) // 60) + \"min)\")\n",
    "        zipped_coords_and_labels = list(zip(self.coords, self.labels))\n",
    "        random.shuffle(zipped_coords_and_labels)\n",
    "        self.coords = [pair[0] for pair in zipped_coords_and_labels]\n",
    "        self.labels = [pair[1] for pair in zipped_coords_and_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def default_model(sequence_length = 200, num_filters = 240, filter_size = 20, dense1_nodes = 1024, dense2_nodes = 512, dense3_nodes = 128, num_outputs = 4, stride = 10, pool_len = 10):\n",
    "    # start by defining input layer, which will read in one-hot encoded sequences\n",
    "    seq_input = Input(shape = (sequence_length, 4, ), name = 'seq')\n",
    "    # the first layer is convolutional\n",
    "    seq = Conv1D(num_filters, filter_size, padding = \"same\")(seq_input)\n",
    "    seq2 = Activation(\"relu\")(seq)\n",
    "    # pool to decrease size (keep strides <= pool_size)\n",
    "    seq3 = MaxPooling1D(padding = \"same\", strides = stride, pool_size = pool_len)(seq2)\n",
    "    # pyramid of dense layers with decreasing #s of nodes\n",
    "    reshaped = Reshape((int(num_filters * sequence_length / stride), ))(seq3)\n",
    "    dense1 = Dense(dense1_nodes, activation = \"relu\")(reshaped)\n",
    "    dense2 = Dense(dense2_nodes, activation = \"relu\")(dense1)\n",
    "    dense3 = Dense(dense3_nodes, activation = \"relu\")(dense2)\n",
    "    # softmax layer output (since we are predicting multiple categories)\n",
    "    # use with categorical_crossentropy loss\n",
    "    output = Dense(num_outputs, activation = \"softmax\")(dense3)\n",
    "    # return model\n",
    "    model = Model(seq_input, output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Set Modification (25-25-25-25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.75\n",
    "\n",
    "training_set = '6col-training-set-eql75.bed'\n",
    "#training_set = '6col-training-set-eql90.bed'\n",
    "#training_set = '6col-training-set-mod85.bed'\n",
    "#training_set = '6col-training-set-mod.bed'\n",
    "#training_set = '6col-training-set.bed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('6col-training-set.bed', 'r') as f:\n",
    "    training = f.readlines()\n",
    "for i in range(len(training)):\n",
    "    training[i] = training[i].split()\n",
    "    for j in range(len(training[i])):\n",
    "        if (j == 1 or j == 2 or j > 6):\n",
    "            training[i][j] = int(training[i][j])\n",
    "        elif (j > 2):\n",
    "            training[i][j] = float(training[i][j])\n",
    "training[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce(file, interval, column): #file = list, interval = int, column = int\n",
    "    #print(file[:100])\n",
    "    print(len(file))\n",
    "    counter = 0\n",
    "    newList = []\n",
    "    print(\"creating newList\")\n",
    "    for window in file:\n",
    "        if (window[column] > threshold):\n",
    "            counter += 1\n",
    "            if (counter % interval == 0):\n",
    "                newList.append(window)\n",
    "        else:\n",
    "            newList.append(window)\n",
    "    #print(newList[:100])\n",
    "    print(\"removed items\")\n",
    "    print(len(newList))\n",
    "    #newList[:100]\n",
    "    return newList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dontUseThisCountAll():\n",
    "    counted = [0, 0, 0, 0]\n",
    "    cTotal = 0\n",
    "    counted[0] = !awk '{if ($4 > $threshold) i += 1} END {print i}' 6col-training-set.bed\n",
    "    counted[1] = !awk '{if ($5 > $threshold) i += 1} END {print i}' 6col-training-set.bed\n",
    "    counted[2] = !awk '{if ($6 > $threshold) i += 1} END {print i}' 6col-training-set.bed\n",
    "    counted[3] = !awk '{if ($7 > $threshold) i += 1} END {print i}' 6col-training-set.bed\n",
    "    for i in range(len(counted)):\n",
    "        counted[i] = int(counted[i][0])\n",
    "        #print(type(counted[i]))\n",
    "        cTotal += counted[i]\n",
    "    for item in counted:\n",
    "        print(int(item) / cTotal) #percentage\n",
    "    return counted #value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countAll(file):\n",
    "    counted = [0, 0, 0, 0]\n",
    "    for x in file:\n",
    "        counted[0] += int(x[3] > threshold)\n",
    "        counted[1] += int(x[4] > threshold)\n",
    "        counted[2] += int(x[5] > threshold)\n",
    "        counted[3] += int(x[6] > threshold)\n",
    "    cTotal = counted[0] + counted[1] + counted[2] + counted[3]\n",
    "    for item in counted:\n",
    "        print(item / cTotal)\n",
    "    print(counted)\n",
    "    return counted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def even_out(file): #file = list\n",
    "    count = countAll(file)\n",
    "    minimum = min(count) #this is ingenius; I was going to actually write it out\n",
    "    intervals = [0, 0, 0, 0]\n",
    "    for i in range(len(intervals)):\n",
    "        intervals[i] = round(float(count[i]) / minimum)\n",
    "    print(intervals) #this printed [1005, 5, 1, 19]\n",
    "    newList = file\n",
    "    for i in range(4):\n",
    "        newList = reduce(newList, intervals[i], i + 3)\n",
    "    return newList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a= !awk '{if ($4 > $threshold) i += 1} END {print i}' 6col-training-set.bed\n",
    "#!awk '{if ($5 > $threshold) i += 1} END {print i}' 6col-training-set.bed\n",
    "#c = !awk '{if ($6 > $threshold) i += 1} END {print i}' 6col-training-set.bed\n",
    "#d = !awk '{if ($7 > $threshold) i += 1} END {print i}' 6col-training-set.bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(a)\n",
    "#print(b)\n",
    "#print(c)\n",
    "#print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "newTrainingList = even_out(training)\n",
    "print(len(newTrainingList))\n",
    "newTrainingList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countAll(newTrainingList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(training_set):\n",
    "    os.remove(training_set)\n",
    "\n",
    "myFile = open(training_set,'w')\n",
    "\n",
    "for window in newTrainingList:\n",
    "    val = [str(item) for item in window]\n",
    "    myFile.write('\\t'.join(val) + '\\n')\n",
    "myFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['chr6',\n",
       "  41028294,\n",
       "  41028494,\n",
       "  0.0,\n",
       "  0.7345679012345679,\n",
       "  0.0,\n",
       "  0.2654320987654321,\n",
       "  0,\n",
       "  1],\n",
       " ['chr6',\n",
       "  41028494,\n",
       "  41028694,\n",
       "  0.5951903807615231,\n",
       "  0.40480961923847697,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1,\n",
       "  0],\n",
       " ['chr6',\n",
       "  41030294,\n",
       "  41030494,\n",
       "  0.565922920892495,\n",
       "  0.4340770791075051,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1,\n",
       "  0],\n",
       " ['chr6',\n",
       "  41030394,\n",
       "  41030594,\n",
       "  0.565922920892495,\n",
       "  0.4340770791075051,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1,\n",
       "  0],\n",
       " ['chr6',\n",
       "  41030594,\n",
       "  41030794,\n",
       "  0.5951903807615231,\n",
       "  0.40480961923847697,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1,\n",
       "  0],\n",
       " ['chr6',\n",
       "  41031994,\n",
       "  41032194,\n",
       "  0.5903614457831325,\n",
       "  0.40963855421686746,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1,\n",
       "  0],\n",
       " ['chr6',\n",
       "  41032794,\n",
       "  41032994,\n",
       "  0.5460122699386503,\n",
       "  0.4539877300613497,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1,\n",
       "  0],\n",
       " ['chr6', 41033094, 41033294, 0.74, 0.26, 0.0, 0.0, 1, 0],\n",
       " ['chr6',\n",
       "  41033594,\n",
       "  41033794,\n",
       "  0.704225352112676,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.29577464788732394,\n",
       "  1,\n",
       "  0],\n",
       " ['chr6',\n",
       "  41033626,\n",
       "  41033826,\n",
       "  0.6666666666666666,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.3333333333333333,\n",
       "  1,\n",
       "  0],\n",
       " ['chr6',\n",
       "  41033694,\n",
       "  41033894,\n",
       "  0.62,\n",
       "  0.04666666666666667,\n",
       "  0.0,\n",
       "  0.3333333333333333,\n",
       "  1,\n",
       "  0],\n",
       " ['chr6',\n",
       "  41033726,\n",
       "  41033926,\n",
       "  0.5133333333333333,\n",
       "  0.15333333333333332,\n",
       "  0.0,\n",
       "  0.3333333333333333,\n",
       "  1,\n",
       "  0],\n",
       " ['chr6',\n",
       "  41033794,\n",
       "  41033994,\n",
       "  0.2866666666666667,\n",
       "  0.38,\n",
       "  0.0,\n",
       "  0.3333333333333333,\n",
       "  1,\n",
       "  0],\n",
       " ['chr6',\n",
       "  41033826,\n",
       "  41034026,\n",
       "  0.18,\n",
       "  0.4866666666666667,\n",
       "  0.0,\n",
       "  0.3333333333333333,\n",
       "  1,\n",
       "  0],\n",
       " ['chr6',\n",
       "  41033894,\n",
       "  41034094,\n",
       "  0.0,\n",
       "  0.6666666666666666,\n",
       "  0.0,\n",
       "  0.3333333333333333,\n",
       "  0,\n",
       "  0],\n",
       " ['chr6',\n",
       "  41033926,\n",
       "  41034126,\n",
       "  0.0,\n",
       "  0.6666666666666666,\n",
       "  0.0,\n",
       "  0.3333333333333333,\n",
       "  0,\n",
       "  0],\n",
       " ['chr6',\n",
       "  41033994,\n",
       "  41034194,\n",
       "  0.065,\n",
       "  0.6233333333333333,\n",
       "  0.0,\n",
       "  0.31166666666666665,\n",
       "  1,\n",
       "  0],\n",
       " ['chr6',\n",
       "  41034026,\n",
       "  41034226,\n",
       "  0.225,\n",
       "  0.5166666666666667,\n",
       "  0.0,\n",
       "  0.25833333333333336,\n",
       "  1,\n",
       "  0],\n",
       " ['chr6', 41034094, 41034294, 0.565, 0.29, 0.0, 0.145, 1, 0],\n",
       " ['chr6',\n",
       "  41034126,\n",
       "  41034326,\n",
       "  0.725,\n",
       "  0.18333333333333332,\n",
       "  0.0,\n",
       "  0.09166666666666666,\n",
       "  1,\n",
       "  0],\n",
       " ['chr6', 41034594, 41034794, 0.475, 0.35, 0.0, 0.175, 1, 0],\n",
       " ['chr6',\n",
       "  41034626,\n",
       "  41034826,\n",
       "  0.315,\n",
       "  0.45666666666666667,\n",
       "  0.0,\n",
       "  0.22833333333333333,\n",
       "  1,\n",
       "  0],\n",
       " ['chr6',\n",
       "  41034694,\n",
       "  41034894,\n",
       "  0.0,\n",
       "  0.6666666666666666,\n",
       "  0.0,\n",
       "  0.3333333333333333,\n",
       "  0,\n",
       "  0],\n",
       " ['chr6',\n",
       "  41034726,\n",
       "  41034926,\n",
       "  0.0,\n",
       "  0.6666666666666666,\n",
       "  0.0,\n",
       "  0.3333333333333333,\n",
       "  0,\n",
       "  0],\n",
       " ['chr6',\n",
       "  41034794,\n",
       "  41034994,\n",
       "  0.0,\n",
       "  0.6666666666666666,\n",
       "  0.0,\n",
       "  0.3333333333333333,\n",
       "  0,\n",
       "  0],\n",
       " ['chr6',\n",
       "  41034826,\n",
       "  41035026,\n",
       "  0.0,\n",
       "  0.6666666666666666,\n",
       "  0.0,\n",
       "  0.3333333333333333,\n",
       "  0,\n",
       "  0],\n",
       " ['chr6',\n",
       "  41034894,\n",
       "  41035094,\n",
       "  0.0,\n",
       "  0.6,\n",
       "  0.06666666666666667,\n",
       "  0.3333333333333333,\n",
       "  0,\n",
       "  1],\n",
       " ['chr6',\n",
       "  41034926,\n",
       "  41035126,\n",
       "  0.0,\n",
       "  0.49333333333333335,\n",
       "  0.17333333333333334,\n",
       "  0.3333333333333333,\n",
       "  0,\n",
       "  1],\n",
       " ['chr6',\n",
       "  41034994,\n",
       "  41035194,\n",
       "  0.21811460258780038,\n",
       "  0.2957486136783734,\n",
       "  0.2255083179297597,\n",
       "  0.26062846580406657,\n",
       "  1,\n",
       "  1],\n",
       " ['chr6',\n",
       "  41035026,\n",
       "  41035226,\n",
       "  0.3575638506876228,\n",
       "  0.18860510805500982,\n",
       "  0.23968565815324164,\n",
       "  0.21414538310412573,\n",
       "  1,\n",
       "  1],\n",
       " ['chr6',\n",
       "  41035094,\n",
       "  41035294,\n",
       "  0.7210884353741497,\n",
       "  0.0,\n",
       "  0.18594104308390022,\n",
       "  0.09297052154195011,\n",
       "  1,\n",
       "  0],\n",
       " ['chr6',\n",
       "  41042426,\n",
       "  41042626,\n",
       "  0.4807692307692308,\n",
       "  0.0,\n",
       "  0.5192307692307693,\n",
       "  0.0,\n",
       "  1,\n",
       "  0],\n",
       " ['chr6',\n",
       "  41042466,\n",
       "  41042666,\n",
       "  0.4032258064516129,\n",
       "  0.0,\n",
       "  0.5967741935483871,\n",
       "  0.0,\n",
       "  1,\n",
       "  0],\n",
       " ['chr6',\n",
       "  41042526,\n",
       "  41042726,\n",
       "  0.35398230088495575,\n",
       "  0.0,\n",
       "  0.6460176991150443,\n",
       "  0.0,\n",
       "  1,\n",
       "  0],\n",
       " ['chr6',\n",
       "  41042566,\n",
       "  41042766,\n",
       "  0.31007751937984496,\n",
       "  0.0,\n",
       "  0.689922480620155,\n",
       "  0.0,\n",
       "  1,\n",
       "  0],\n",
       " ['chr6',\n",
       "  41042626,\n",
       "  41042826,\n",
       "  0.44287729196050774,\n",
       "  0.0,\n",
       "  0.5571227080394923,\n",
       "  0.0,\n",
       "  1,\n",
       "  0],\n",
       " ['chr6',\n",
       "  41042666,\n",
       "  41042866,\n",
       "  0.5794392523364486,\n",
       "  0.0,\n",
       "  0.4205607476635514,\n",
       "  0.0,\n",
       "  1,\n",
       "  0],\n",
       " ['chr6', 41042866, 41043066, 0.62125, 0.30375, 0.075, 0.0, 1, 1],\n",
       " ['chr6', 41042926, 41043126, 0.39625, 0.52875, 0.075, 0.0, 1, 1],\n",
       " ['chr6', 41042966, 41043166, 0.28, 0.64875, 0.07125, 0.0, 1, 1],\n",
       " ['chr6', 41043026, 41043226, 0.505, 0.495, 0.0, 0.0, 1, 0],\n",
       " ['chr6', 41043066, 41043266, 0.655, 0.345, 0.0, 0.0, 1, 0],\n",
       " ['chr6', 41043466, 41043666, 0.725, 0.275, 0.0, 0.0, 1, 0],\n",
       " ['chr6', 41043526, 41043726, 0.645, 0.355, 0.0, 0.0, 1, 0],\n",
       " ['chr6', 41043566, 41043766, 0.67, 0.33, 0.0, 0.0, 1, 0],\n",
       " ['chr6', 41043826, 41044026, 0.67375, 0.26375, 0.0, 0.0625, 1, 1],\n",
       " ['chr6', 41043866, 41044066, 0.52375, 0.36375, 0.0, 0.1125, 1, 1],\n",
       " ['chr6', 41043926, 41044126, 0.29875, 0.51375, 0.0, 0.1875, 1, 1],\n",
       " ['chr6', 41043966, 41044166, 0.25, 0.4325, 0.0, 0.3175, 1, 1],\n",
       " ['chr6',\n",
       "  41044026,\n",
       "  41044226,\n",
       "  0.2544529262086514,\n",
       "  0.2748091603053435,\n",
       "  0.0,\n",
       "  0.4707379134860051,\n",
       "  1,\n",
       "  1],\n",
       " ['chr6',\n",
       "  41044066,\n",
       "  41044266,\n",
       "  0.2717391304347826,\n",
       "  0.18478260869565216,\n",
       "  0.0,\n",
       "  0.5434782608695652,\n",
       "  1,\n",
       "  1],\n",
       " ['chr6',\n",
       "  41044126,\n",
       "  41044326,\n",
       "  0.3246753246753247,\n",
       "  0.025974025974025976,\n",
       "  0.0,\n",
       "  0.6493506493506493,\n",
       "  1,\n",
       "  1],\n",
       " ['chr6',\n",
       "  41044226,\n",
       "  41044426,\n",
       "  0.5865102639296188,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.41348973607038125,\n",
       "  1,\n",
       "  0],\n",
       " ['chr6', 41052126, 41052326, 0.69, 0.235, 0.0, 0.075, 1, 1],\n",
       " ['chr6', 41052226, 41052426, 0.505, 0.42, 0.0, 0.075, 1, 1],\n",
       " ['chr6',\n",
       "  41053226,\n",
       "  41053426,\n",
       "  0.6191950464396285,\n",
       "  0.24458204334365324,\n",
       "  0.13622291021671826,\n",
       "  0.0,\n",
       "  1,\n",
       "  1],\n",
       " ['chr6', 41053303, 41053503, 0.5625, 0.3275, 0.11, 0.0, 1, 1],\n",
       " ['chr6', 41053326, 41053526, 0.62, 0.3275, 0.0525, 0.0, 1, 1],\n",
       " ['chr6', 41061303, 41061503, 0.56, 0.44, 0.0, 0.0, 1, 0],\n",
       " ['chr6', 41061326, 41061526, 0.5025, 0.4975, 0.0, 0.0, 1, 0],\n",
       " ['chr6', 41061403, 41061603, 0.5, 0.5, 0.0, 0.0, 1, 0],\n",
       " ['chr6', 41061426, 41061626, 0.5, 0.5, 0.0, 0.0, 1, 0],\n",
       " ['chr6', 41061503, 41061703, 0.5, 0.5, 0.0, 0.0, 1, 0],\n",
       " ['chr6', 41061526, 41061726, 0.5, 0.5, 0.0, 0.0, 1, 0],\n",
       " ['chr6', 41061603, 41061803, 0.5, 0.5, 0.0, 0.0, 1, 0],\n",
       " ['chr6', 41061626, 41061826, 0.5, 0.5, 0.0, 0.0, 1, 0],\n",
       " ['chr6', 41061703, 41061903, 0.5275, 0.4125, 0.0, 0.06, 1, 1],\n",
       " ['chr6', 41061726, 41061926, 0.585, 0.355, 0.0, 0.06, 1, 1],\n",
       " ['chr6', 41064003, 41064203, 0.7425, 0.0, 0.0, 0.2575, 1, 0],\n",
       " ['chr6', 41064026, 41064226, 0.685, 0.0, 0.0, 0.315, 1, 0],\n",
       " ['chr6', 41064103, 41064303, 0.5, 0.0, 0.0, 0.5, 1, 0],\n",
       " ['chr6', 41064126, 41064326, 0.5, 0.0, 0.0, 0.5, 1, 0],\n",
       " ['chr6', 41064203, 41064403, 0.5, 0.0, 0.0, 0.5, 1, 0],\n",
       " ['chr6', 41064226, 41064426, 0.5, 0.0, 0.0, 0.5, 1, 0],\n",
       " ['chr6', 41064303, 41064503, 0.5, 0.0, 0.0, 0.5, 1, 0],\n",
       " ['chr6',\n",
       "  41064326,\n",
       "  41064526,\n",
       "  0.5194805194805194,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.4805194805194805,\n",
       "  1,\n",
       "  0],\n",
       " ['chr6',\n",
       "  41064426,\n",
       "  41064626,\n",
       "  0.7017543859649122,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.2982456140350877,\n",
       "  1,\n",
       "  0],\n",
       " ['chr6',\n",
       "  41064626,\n",
       "  41064826,\n",
       "  0.6578947368421053,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.34210526315789475,\n",
       "  1,\n",
       "  0],\n",
       " ['chr6',\n",
       "  41064726,\n",
       "  41064926,\n",
       "  0.3968253968253968,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.6031746031746031,\n",
       "  1,\n",
       "  0],\n",
       " ['chr6',\n",
       "  41064826,\n",
       "  41065026,\n",
       "  0.3333333333333333,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.6666666666666666,\n",
       "  1,\n",
       "  0],\n",
       " ['chr6',\n",
       "  41064926,\n",
       "  41065126,\n",
       "  0.3333333333333333,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.6666666666666666,\n",
       "  1,\n",
       "  0],\n",
       " ['chr6',\n",
       "  41065026,\n",
       "  41065226,\n",
       "  0.3333333333333333,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.6666666666666666,\n",
       "  1,\n",
       "  0],\n",
       " ['chr6',\n",
       "  41065126,\n",
       "  41065326,\n",
       "  0.3333333333333333,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.6666666666666666,\n",
       "  1,\n",
       "  0],\n",
       " ['chr6',\n",
       "  41065226,\n",
       "  41065426,\n",
       "  0.3333333333333333,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.6666666666666666,\n",
       "  1,\n",
       "  0],\n",
       " ['chr6',\n",
       "  41065326,\n",
       "  41065526,\n",
       "  0.3333333333333333,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.6666666666666666,\n",
       "  1,\n",
       "  0],\n",
       " ['chr6',\n",
       "  41065426,\n",
       "  41065626,\n",
       "  0.3333333333333333,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.6666666666666666,\n",
       "  1,\n",
       "  0],\n",
       " ['chr6',\n",
       "  41065526,\n",
       "  41065726,\n",
       "  0.3333333333333333,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.6666666666666666,\n",
       "  1,\n",
       "  0],\n",
       " ['chr6',\n",
       "  41065626,\n",
       "  41065826,\n",
       "  0.3333333333333333,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.6666666666666666,\n",
       "  1,\n",
       "  0],\n",
       " ['chr6',\n",
       "  41065726,\n",
       "  41065926,\n",
       "  0.3333333333333333,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.6666666666666666,\n",
       "  1,\n",
       "  0],\n",
       " ['chr6',\n",
       "  41065826,\n",
       "  41066026,\n",
       "  0.3333333333333333,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.6666666666666666,\n",
       "  1,\n",
       "  0],\n",
       " ['chr6',\n",
       "  41065926,\n",
       "  41066126,\n",
       "  0.3333333333333333,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.6666666666666666,\n",
       "  1,\n",
       "  0],\n",
       " ['chr6',\n",
       "  41066026,\n",
       "  41066226,\n",
       "  0.3333333333333333,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.6666666666666666,\n",
       "  1,\n",
       "  0],\n",
       " ['chr6',\n",
       "  41066126,\n",
       "  41066326,\n",
       "  0.3333333333333333,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.6666666666666666,\n",
       "  1,\n",
       "  0],\n",
       " ['chr6',\n",
       "  41066226,\n",
       "  41066426,\n",
       "  0.3333333333333333,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.6666666666666666,\n",
       "  1,\n",
       "  0],\n",
       " ['chr6',\n",
       "  41066326,\n",
       "  41066526,\n",
       "  0.3067484662576687,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.6932515337423313,\n",
       "  1,\n",
       "  0],\n",
       " ['chr6',\n",
       "  41066426,\n",
       "  41066626,\n",
       "  0.26595744680851063,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.7340425531914894,\n",
       "  1,\n",
       "  0],\n",
       " ['chr6', 41066526, 41066726, 0.25, 0.0, 0.0, 0.75, 1, 0],\n",
       " ['chr6',\n",
       "  41066726,\n",
       "  41066926,\n",
       "  0.1863932898415657,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.8136067101584343,\n",
       "  1,\n",
       "  0],\n",
       " ['chr6',\n",
       "  41067226,\n",
       "  41067426,\n",
       "  0.08984725965858041,\n",
       "  0.24932614555256064,\n",
       "  0.0,\n",
       "  0.660826594788859,\n",
       "  1,\n",
       "  1],\n",
       " ['chr6',\n",
       "  41067326,\n",
       "  41067526,\n",
       "  0.5068787618228718,\n",
       "  0.29062768701633707,\n",
       "  0.0,\n",
       "  0.20249355116079107,\n",
       "  1,\n",
       "  1]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(training_set, 'r') as f:\n",
    "    training2 = f.readlines()\n",
    "for i in range(len(training2)):\n",
    "    training2[i] = training2[i].split()\n",
    "    for j in range(len(training2[i])):\n",
    "        if (j == 1 or j == 2 or j > 6):\n",
    "            training2[i][j] = int(training2[i][j])\n",
    "        elif (j > 2):\n",
    "            training2[i][j] = float(training2[i][j])\n",
    "training2[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "425226\n",
      "0.25039760501450087\n",
      "0.25105248386191414\n",
      "0.25025727383291235\n",
      "0.24829263729067266\n",
      "[10706, 10734, 10700, 10616]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[10706, 10734, 10700, 10616]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(training2))\n",
    "countAll(training2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity Check\n",
    "ignore this - no longer relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(training_set, 'r') as f:\n",
    "    train_mod = f.readlines()\n",
    "for i in range(len(train_mod)):\n",
    "    train_mod[i] = train_mod[i].split()\n",
    "    for j in range(len(train_mod[i])):\n",
    "        if (j == 1 or j == 2 or j > 6):\n",
    "            train_mod[i][j] = int(train_mod[i][j])\n",
    "        elif (j > 2):\n",
    "            train_mod[i][j] = float(train_mod[i][j])\n",
    "train_mod[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training should've been opened in the above section\n",
    "counter = [0, 0, 0, 0]\n",
    "countAll = 0\n",
    "for x in training:\n",
    "    counter[0] += int(float(x[3]) > threshold)\n",
    "    counter[1] += int(float(x[4]) > threshold)\n",
    "    counter[2] += int(float(x[5]) > threshold)\n",
    "    counter[3] += int(float(x[6]) > threshold)\n",
    "    countAll += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter2 = [0, 0, 0, 0]\n",
    "countAll2 = 0\n",
    "for x in train_mod:\n",
    "    counter2[0] += int(float(x[3]) > threshold)\n",
    "    counter2[1] += int(float(x[4]) > threshold)\n",
    "    counter2[2] += int(float(x[5]) > threshold)\n",
    "    counter2[3] += int(float(x[6]) > threshold)\n",
    "countAll2 = counter2[0] + counter2[1] + counter2[2] + counter2[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(counter2[0]/countAll2)\n",
    "print(counter2[1]/countAll2)\n",
    "print(counter2[2]/countAll2)\n",
    "print(counter2[3]/countAll2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DO NOT RUN THE CELL BELOW!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what I expected to get\n",
    "A\n",
    "B\n",
    "A/B             #somewhere between 0.9 and 1\n",
    "A/2\n",
    "B-(A/2)\n",
    "(A/2)/(B-(A/2)) #somewhere between 0.7 and 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (not (os.path.isfile('GRCh38.p13.genome.fa.gz') or os.path.isfile('GRCh38.p13.genome.fa'))):\n",
    "    !wget ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_34/GRCh38.p13.genome.fa.gz\n",
    "if (not os.path.isfile('GRCh38.p13.genome.fa') and os.path.isfile('GRCh38.p13.genome.fa.gz')):\n",
    "    !gunzip GRCh38.p13.genome.fa.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "425226"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_examples = !wc -l < $training_set\n",
    "training_examples = int(training_examples[0])\n",
    "training_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "batchsize = 200 #for now\n",
    "train_steps = training_examples // batchsize\n",
    "num_epochs = 10 #for now #1000\n",
    "#threshold defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6col-training-set-eql75.bed\n"
     ]
    }
   ],
   "source": [
    "print(training_set) #just double-checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.engine.functional.Functional object at 0x7f98231405d0>\n",
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "seq (InputLayer)             [(None, 200, 4)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 200, 240)          19440     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 200, 240)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 20, 240)           0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 4800)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              4916224   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 5,526,644\n",
      "Trainable params: 5,526,644\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "running get_coords(0sec)\n",
      "running on_epoch_end(0min)\n",
      "running __len__\n",
      "Epoch 1/10\n",
      "running __len__\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "2126/2126 - 85s - loss: 0.1400 - accuracy: 0.0265\n",
      "running on_epoch_end(1min)\n",
      "Epoch 2/10\n",
      "running __len__\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "2126/2126 - 86s - loss: 0.1401 - accuracy: 0.0255\n",
      "running on_epoch_end(2min)\n",
      "Epoch 3/10\n",
      "running __len__\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "2126/2126 - 85s - loss: 0.1404 - accuracy: 0.0253\n",
      "running on_epoch_end(4min)\n",
      "Epoch 4/10\n",
      "running __len__\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "2126/2126 - 84s - loss: 0.1403 - accuracy: 0.0252\n",
      "running on_epoch_end(5min)\n",
      "Epoch 5/10\n",
      "running __len__\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "2126/2126 - 86s - loss: 0.1405 - accuracy: 0.0252\n",
      "running on_epoch_end(7min)\n",
      "Epoch 6/10\n",
      "running __len__\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "2126/2126 - 85s - loss: 0.1406 - accuracy: 0.0252\n",
      "running on_epoch_end(8min)\n",
      "Epoch 7/10\n",
      "running __len__\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "2126/2126 - 84s - loss: 0.1406 - accuracy: 0.0253\n",
      "running on_epoch_end(10min)\n",
      "Epoch 8/10\n",
      "running __len__\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "2126/2126 - 88s - loss: 0.1404 - accuracy: 0.0253\n",
      "running on_epoch_end(11min)\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "running on_epoch_end(11min)\n",
      "Epoch 9/10\n",
      "running __len__\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "2126/2126 - 86s - loss: 0.1405 - accuracy: 0.0253\n",
      "running on_epoch_end(13min)\n",
      "Epoch 10/10\n",
      "running __len__\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "running on_epoch_end(14min)\n",
      "2126/2126 - 86s - loss: 0.1406 - accuracy: 0.0253\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "running on_epoch_end(14min)\n"
     ]
    }
   ],
   "source": [
    "model = default_model()\n",
    "print(model)\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = Adam(learning_rate=0.0000001), metrics = [\"accuracy\"])\n",
    "print(model.summary())\n",
    "start = time.time()\n",
    "hist = model.fit_generator(epochs = num_epochs,  # choose how many epochs to train for (watch the loss to see when to stop)\n",
    "                           steps_per_epoch = train_steps,\n",
    "                           generator = TrainGenerator(),  # see above\n",
    "                           use_multiprocessing = True,\n",
    "                           workers = 8,  # use this to split batch processing into multiple CPUs (but don't take over the VM completely!)\n",
    "                           verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to-do after this (DO NOT RESTART KERNEL)\n",
    "#check to see if test generator works\n",
    "#check to see if confusion matrix works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(hist, cb = None):\n",
    "    epochs = range(1, 100) #1, num_epochs + 1\n",
    "    plt.figure(figsize = (12,8))\n",
    "    plt.subplot(211)\n",
    "    plt.plot(epochs, hist.history[\"accuracy\"], '.-', color = '#31E080', label = \"Training Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.subplot(212)\n",
    "    plt.plot(epochs, hist.history[\"loss\"], '.-', color = '#31E080', label = \"Training Loss\")\n",
    "    plt.legend()\n",
    "    plt.legend()\n",
    "    plt.savefig(params.figures_path + \"_metrics\", dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_metrics(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.14004182815551758,\n",
       "  0.14010311663150787,\n",
       "  0.14041081070899963,\n",
       "  0.14030897617340088,\n",
       "  0.14046761393547058,\n",
       "  0.14059388637542725,\n",
       "  0.1405787169933319,\n",
       "  0.1403840184211731,\n",
       "  0.1404883861541748,\n",
       "  0.14063170552253723],\n",
       " 'accuracy': [0.026467544957995415,\n",
       "  0.025526810437440872,\n",
       "  0.02527751587331295,\n",
       "  0.025242239236831665,\n",
       "  0.025244589895009995,\n",
       "  0.025246942415833473,\n",
       "  0.02525164559483528,\n",
       "  0.025291627272963524,\n",
       "  0.025310441851615906,\n",
       "  0.025322200730443]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation/Test Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set = '6col-validation-set.bed'\n",
    "test_set = '6col-test-set.bed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestGenerator(Sequence):\n",
    "    def __init__(self):\n",
    "        self.testingfile = test_set\n",
    "        self.converter = PyfaidxCoordsToVals('GRCh38.p13.genome.fa')\n",
    "        self.batchsize = batchsize\n",
    "        self.steps_per_epoch = train_steps\n",
    "        self.total_epochs = num_epochs  # how many epochs to train for (you're using enough epochs when the loss stops going down)\n",
    "        self.get_coords()\n",
    "        self.on_epoch_end()\n",
    "    def __len__(self):  # required by Keras -- returns # of batches to expect\n",
    "        print('running __len__')\n",
    "        return self.steps_per_epoch\n",
    "    def get_coords(self):\n",
    "        print(\"running get_coords\")\n",
    "        with open(self.testingfile) as testf:\n",
    "            #self.labels = [int(line.split()[-6:]) for line in testf]  # assumes last columns in file are the labels, and assumes 6 label columns\n",
    "            #coords_tmp = [line.split()[:3] for line in testf]\n",
    "            #self.coords = [Coordinates(coord[0], int(coord[1]), int(coord[2])) for coord in coords_tmp]\n",
    "            self.coords = []\n",
    "            for line in testf:\n",
    "                temp = line.split()\n",
    "                tempList = [temp[0], int(temp[1]), int(temp[2])]\n",
    "                self.coords.append(Coordinates(tempList[0], tempList[1], tempList[2]))\n",
    "            #should I cast them as numpy arrays?\n",
    "    def __getitem__(self, batch_index):\n",
    "        ##print(\"running __getitem__\")\n",
    "        # get one-hot encoded sequences, using coordinates, for the next batch\n",
    "        seqs_onehot = self.converter(self.coords[batch_index * self.batchsize : (batch_index + 1) * self.batchsize])\n",
    "        \n",
    "        # sanity checks\n",
    "        assert seqs_onehot.shape[0] == self.batchsize\n",
    "        return seqs_onehot\n",
    "    def on_epoch_end(self):\n",
    "        # shuffle labels and coordinates (together) between epochs\n",
    "        print(\"running on_epoch_end\")\n",
    "        random.shuffle(self.coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running get_coords\n",
      "running on_epoch_end\n",
      "running __len__\n",
      "running __len__\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "running on_epoch_end\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict_generator(generator = TestGenerator(),  # see above\n",
    "                           use_multiprocessing = True,\n",
    "                           workers = 8)  # use this to split batch processing into multiple CPUs (but don't take over the VM completely!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1700800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.2250703 , 0.31587446, 0.24309179, 0.21596345],\n",
       "       [0.21879609, 0.32358792, 0.25067016, 0.20694582],\n",
       "       [0.20701739, 0.31128842, 0.27407414, 0.20762004],\n",
       "       ...,\n",
       "       [0.20041926, 0.3138206 , 0.2713592 , 0.2144009 ],\n",
       "       [0.20807523, 0.3087306 , 0.26645428, 0.21673986],\n",
       "       [0.2124725 , 0.33845934, 0.24588688, 0.20318128]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(prediction.size)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_test_set_prediction_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1960396 6col-test-set.bed\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l $test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#note: the matrix below is NOT the correct one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 1],\n",
       "       [1, 2, 1, 3],\n",
       "       [0, 3, 2, 1],\n",
       "       [3, 0, 1, 0]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = [\"intron\", \"CDS\", \"CDS\", \"5' UTR\", \"CDS\", \"CDS\", \"CDS\", \"5' UTR\", \"5' UTR\", \"3' UTR\", \"3' UTR\", \"CDS\", \"3' UTR\", \"5' UTR\", \"5' UTR\", \"intron\", \"CDS\", \"3' UTR\", \"5' UTR\"]\n",
    "y_pred = [\"3' UTR\", \"CDS\", \"3' UTR\", \"CDS\", \"5' UTR\", \"CDS\", \"intron\", \"3' UTR\", \"CDS\", \"intron\", \"intron\", \"3' UTR\", \"intron\", \"CDS\", \"5' UTR\", \"CDS\", \"3' UTR\", \"5' UTR\", \"5' UTR\"]\n",
    "myLabels = [\"intron\", \"CDS\", \"5' UTR\", \"3' UTR\"]\n",
    "cm = confusion_matrix(y_true, y_pred, labels=myLabels)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cm)\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + myLabels)\n",
    "ax.set_yticklabels([''] + myLabels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
