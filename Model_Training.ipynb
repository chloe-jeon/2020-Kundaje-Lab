{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"15\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import Sequence\n",
    "from keras.layers import Dense, Activation, Input, Conv1D, MaxPooling1D, Reshape\n",
    "from keras.optimizers import Adam\n",
    "from keras import Model\n",
    "import numpy as np\n",
    "from seqdataloader.batchproducers.coordbased.core import Coordinates\n",
    "from seqdataloader.batchproducers.coordbased.coordstovals.fasta import PyfaidxCoordsToVals\n",
    "from pyfaidx import Fasta\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainGenerator(Sequence):\n",
    "    def __init__(self):\n",
    "        self.trainingfile = training_set\n",
    "        self.converter = PyfaidxCoordsToVals('GRCh38.p13.genome.fa')\n",
    "        self.batchsize = batchsize\n",
    "        self.steps_per_epoch = train_steps\n",
    "        self.total_epochs = num_epochs  # how many epochs to train for (you're using enough epochs when the loss stops going down)\n",
    "        self.get_coords()\n",
    "        self.on_epoch_end()\n",
    "    def __len__(self):  # required by Keras -- returns # of batches to expect\n",
    "        print('running __len__')\n",
    "        return self.steps_per_epoch\n",
    "    def get_coords(self):\n",
    "        print(\"running get_coords\")\n",
    "        with open(self.trainingfile) as trainf:\n",
    "            #self.labels = [int(line.split()[-6:]) for line in trainf]  # assumes last columns in file are the labels, and assumes 6 label columns\n",
    "            #coords_tmp = [line.split()[:3] for line in trainf]\n",
    "            #self.coords = [Coordinates(coord[0], int(coord[1]), int(coord[2])) for coord in coords_tmp]\n",
    "            self.labels = []\n",
    "            self.coords = []\n",
    "            for line in trainf:\n",
    "                temp = line.split()\n",
    "                tempList = [temp[0], int(temp[1]), int(temp[2]), float(temp[3]), float(temp[4]), \n",
    "                            float(temp[5]), float(temp[6]), int(temp[7]), int(temp[8])]\n",
    "                for ind in range(len(tempList)):\n",
    "                    if (ind < 3 or ind > 6):\n",
    "                        continue\n",
    "                    if (tempList[ind] > threshold):\n",
    "                        tempList[ind] = 1\n",
    "                    else:\n",
    "                        tempList[ind] = 0\n",
    "                    #tempList[ind] = int(tempList[ind])\n",
    "                self.labels.append(tempList[-6:-2]) #4 label columns\n",
    "                self.coords.append(Coordinates(tempList[0], tempList[1], tempList[2]))\n",
    "            #should I cast them as numpy arrays?\n",
    "    def __getitem__(self, batch_index):\n",
    "        print(\"running __getitem__\")\n",
    "        # get one-hot encoded sequences, using coordinates, for the next batch\n",
    "        seqs_onehot = self.converter(self.coords[batch_index * self.batchsize : (batch_index + 1) * self.batchsize])\n",
    "        # get labels for the next batch\n",
    "        labels = self.labels[batch_index * self.batchsize : (batch_index + 1) * self.batchsize]\n",
    "        \n",
    "        if (seqs_onehot.shape[0] == 0):\n",
    "            print(\"DEBUG: seqs_onehot.shape[0] == 0\")\n",
    "            print(\"batch_index: \" + str(batch_index))\n",
    "            print(\"self.batchsize: \" + str(self.batchsize))\n",
    "            print(\"self.coords[batch_index * self.batchsize : (batch_index + 1) * self.batchsize]\")\n",
    "            print(self.coords[batch_index * self.batchsize : (batch_index + 1) * self.batchsize])\n",
    "        \n",
    "        # sanity checks\n",
    "        assert seqs_onehot.shape[0] == np.array(labels).shape[0], (seqs_onehot.shape[0], np.array(labels).shape[0])\n",
    "        assert seqs_onehot.shape[0] == self.batchsize, (seqs_onehot.shape[0], self.batchsize)\n",
    "        return seqs_onehot, np.array(labels) #return all_seqs, np.array(self.labels)\n",
    "    def on_epoch_end(self):\n",
    "        # shuffle labels and coordinates (together) between epochs\n",
    "        print(\"running on_epoch_end\")\n",
    "        zipped_coords_and_labels = list(zip(self.coords, self.labels))\n",
    "        random.shuffle(zipped_coords_and_labels)\n",
    "        self.coords = [pair[0] for pair in zipped_coords_and_labels]\n",
    "        self.labels = [pair[1] for pair in zipped_coords_and_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def default_model(sequence_length = 200, num_filters = 240, filter_size = 20, dense1_nodes = 1024, dense2_nodes = 512, dense3_nodes = 128, num_outputs = 4, stride = 10, pool_len = 10):\n",
    "    # start by defining input layer, which will read in one-hot encoded sequences\n",
    "    seq_input = Input(shape = (sequence_length, 4, ), name = 'seq')\n",
    "    # the first layer is convolutional\n",
    "    seq = Conv1D(num_filters, filter_size, padding = \"same\")(seq_input)\n",
    "    seq2 = Activation(\"relu\")(seq)\n",
    "    # pool to decrease size (keep strides <= pool_size)\n",
    "    seq3 = MaxPooling1D(padding = \"same\", strides = stride, pool_size = pool_len)(seq2)\n",
    "    # pyramid of dense layers with decreasing #s of nodes\n",
    "    reshaped = Reshape((int(num_filters * sequence_length / stride), ))(seq3)\n",
    "    dense1 = Dense(dense1_nodes, activation = \"relu\")(reshaped)\n",
    "    dense2 = Dense(dense2_nodes, activation = \"relu\")(dense1)\n",
    "    dense3 = Dense(dense3_nodes, activation = \"relu\")(dense2)\n",
    "    # softmax layer output (since we are predicting multiple categories)\n",
    "    # use with categorical_crossentropy loss\n",
    "    output = Dense(num_outputs, activation = \"softmax\")(dense3)\n",
    "    # return model\n",
    "    model = Model(seq_input, output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Set Modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('6col-training-set.bed', 'r') as f:\n",
    "    training = f.readlines()\n",
    "for i in range(len(training)):\n",
    "    training[i] = training[i].split()\n",
    "    for j in range(len(training[i])):\n",
    "        if (j == 1 or j == 2 or j > 6):\n",
    "            training[i][j] = int(training[i][j])\n",
    "        elif (j > 2):\n",
    "            training[i][j] = float(training[i][j])\n",
    "training[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fewerIntrons(file, interval): #after opening and saving as list\n",
    "    #print(file[:100])\n",
    "    print(len(file))\n",
    "    counter = 0\n",
    "    newList = []\n",
    "    print(\"creating newList\")\n",
    "    for window in file:\n",
    "        if (window[interval] > threshold):\n",
    "            counter += 1\n",
    "        if (counter % interval == 0):\n",
    "            newList.append(window)\n",
    "    #print(newList[:100])\n",
    "    print(\"removing items\")\n",
    "    print(len(newList))\n",
    "    #newList[:100]\n",
    "    return newList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_modified = fewerIntrons(training, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('6col-training-set-mod.bed'):\n",
    "    os.remove('6col-training-set-mod.bed')\n",
    "\n",
    "myFile = open('6col-training-set-mod.bed','w')\n",
    "\n",
    "for window in training_modified:\n",
    "    val = [str(item) for item in window]\n",
    "    myFile.write('\\t'.join(val) + '\\n')\n",
    "myFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = '6col-training-set-mod.bed'\n",
    "#training_set = '6col-training-set.bed'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (not (os.path.isfile('GRCh38.p13.genome.fa.gz') or os.path.isfile('GRCh38.p13.genome.fa'))):\n",
    "    !wget ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_34/GRCh38.p13.genome.fa.gz\n",
    "if (not os.path.isfile('GRCh38.p13.genome.fa') and os.path.isfile('GRCh38.p13.genome.fa.gz')):\n",
    "    !gunzip GRCh38.p13.genome.fa.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_examples = !wc -l < \"6col-training-set.bed\"\n",
    "training_examples = int(training_examples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "batchsize = 200 #for now\n",
    "train_steps = training_examples // batchsize\n",
    "num_epochs = 10 #for now #1000\n",
    "#threshold defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.engine.functional.Functional object at 0x7fc6d5adce10>\n",
      "Model: \"functional_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "seq (InputLayer)             [(None, 200, 4)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 200, 240)          19440     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 200, 240)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 20, 240)           0         \n",
      "_________________________________________________________________\n",
      "reshape_4 (Reshape)          (None, 4800)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1024)              4916224   \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 5,526,644\n",
      "Trainable params: 5,526,644\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "running get_coords\n",
      "running on_epoch_end\n",
      "running __len__\n",
      "running __getitem__\n",
      "Epoch 1/10\n",
      "running __len__\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "running __getitem__running __getitem__\n",
      "running __getitem__\n",
      "\n",
      "running __getitem__running __getitem__\n",
      "\n",
      "running __getitem__running __getitem__DEBUG: seqs_onehot.shape[0] == 0\n",
      "\n",
      "running __getitem__\n",
      "DEBUG: seqs_onehot.shape[0] == 0\n",
      "\n",
      "DEBUG: seqs_onehot.shape[0] == 0batch_index: 23771batch_index: 38053\n",
      "running __getitem__\n",
      "self.batchsize: 200\n",
      "\n",
      "running __getitem__\n",
      "self.coords[batch_index * self.batchsize : (batch_index + 1) * self.batchsize]\n",
      "[]\n",
      "self.batchsize: 200\n",
      "batch_index: 26973running __getitem__\n",
      "\n",
      "\n",
      "self.batchsize: 200DEBUG: seqs_onehot.shape[0] == 0self.coords[batch_index * self.batchsize : (batch_index + 1) * self.batchsize]\n",
      "running __getitem__self.coords[batch_index * self.batchsize : (batch_index + 1) * self.batchsize]\n",
      "\n",
      "\n",
      "\n",
      "[]DEBUG: seqs_onehot.shape[0] == 0batch_index: 36806\n",
      "\n",
      "batch_index: 34501\n",
      "\n",
      "[]\n",
      "self.batchsize: 200self.batchsize: 200\n",
      "\n",
      "DEBUG: seqs_onehot.shape[0] == 0self.coords[batch_index * self.batchsize : (batch_index + 1) * self.batchsize]self.coords[batch_index * self.batchsize : (batch_index + 1) * self.batchsize]\n",
      "\n",
      "[]\n",
      "batch_index: 25340[]\n",
      "\n",
      "self.batchsize: 200\n",
      "\n",
      "self.coords[batch_index * self.batchsize : (batch_index + 1) * self.batchsize]\n",
      "    1/45748 [..............................] - ETA: 12s - loss: 1.3034 - accuracy: 0.0050\n",
      "running __getitem__\n",
      "DEBUG: seqs_onehot.shape[0] == 0\n",
      "batch_index: 33208\n",
      "self.batchsize: 200\n",
      "self.coords[batch_index * self.batchsize : (batch_index + 1) * self.batchsize]\n",
      "[]\n",
      "    2/45748 [..............................] - ETA: 39:53 - loss: 1.3107 - accuracy: 0.0125"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": " AssertionError: (0, 200)\nmultiprocessing.pool.RemoteTraceback: \n\"\"\"\nTraceback (most recent call last):\n  File \"/opt/miniconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/chloe/.local/lib/python3.7/site-packages/tensorflow/python/keras/utils/data_utils.py\", line 679, in get_index\n    return _SHARED_SEQUENCES[uid][i]\n  File \"<ipython-input-17-c10936ee6704>\", line 52, in __getitem__\n    assert seqs_onehot.shape[0] == self.batchsize, (seqs_onehot.shape[0], self.batchsize)\nAssertionError: (0, 200)\n\"\"\"\n\n\nThe above exception was the direct cause of the following exception:\n\n\nTraceback (most recent call last):\n\n  File \"/home/chloe/.local/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 244, in __call__\n    ret = func(*args)\n\n  File \"/home/chloe/.local/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 302, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/chloe/.local/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 827, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/home/chloe/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 814, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/home/chloe/.local/lib/python3.7/site-packages/tensorflow/python/keras/utils/data_utils.py\", line 900, in get\n    six.reraise(*sys.exc_info())\n\n  File \"/home/chloe/.local/lib/python3.7/site-packages/six.py\", line 703, in reraise\n    raise value\n\n  File \"/home/chloe/.local/lib/python3.7/site-packages/tensorflow/python/keras/utils/data_utils.py\", line 891, in get\n    inputs = self.queue.get(block=True, timeout=5).get()\n\n  File \"/opt/miniconda3/lib/python3.7/multiprocessing/pool.py\", line 657, in get\n    raise self._value\n\nAssertionError: (0, 200)\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_4761]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-b180b57ee6ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                            \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# see above\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                            \u001b[0muse_multiprocessing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                            workers = 8)  # use this to split batch processing into multiple CPUs (but don't take over the VM completely!)\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1827\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1828\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1829\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1831\u001b[0m   @deprecation.deprecated(\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m:  AssertionError: (0, 200)\nmultiprocessing.pool.RemoteTraceback: \n\"\"\"\nTraceback (most recent call last):\n  File \"/opt/miniconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/chloe/.local/lib/python3.7/site-packages/tensorflow/python/keras/utils/data_utils.py\", line 679, in get_index\n    return _SHARED_SEQUENCES[uid][i]\n  File \"<ipython-input-17-c10936ee6704>\", line 52, in __getitem__\n    assert seqs_onehot.shape[0] == self.batchsize, (seqs_onehot.shape[0], self.batchsize)\nAssertionError: (0, 200)\n\"\"\"\n\n\nThe above exception was the direct cause of the following exception:\n\n\nTraceback (most recent call last):\n\n  File \"/home/chloe/.local/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 244, in __call__\n    ret = func(*args)\n\n  File \"/home/chloe/.local/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 302, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/chloe/.local/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 827, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/home/chloe/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 814, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/home/chloe/.local/lib/python3.7/site-packages/tensorflow/python/keras/utils/data_utils.py\", line 900, in get\n    six.reraise(*sys.exc_info())\n\n  File \"/home/chloe/.local/lib/python3.7/site-packages/six.py\", line 703, in reraise\n    raise value\n\n  File \"/home/chloe/.local/lib/python3.7/site-packages/tensorflow/python/keras/utils/data_utils.py\", line 891, in get\n    inputs = self.queue.get(block=True, timeout=5).get()\n\n  File \"/opt/miniconda3/lib/python3.7/multiprocessing/pool.py\", line 657, in get\n    raise self._value\n\nAssertionError: (0, 200)\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_4761]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "model = default_model()\n",
    "print(model)\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = Adam(learning_rate=0.000001), metrics = [\"accuracy\"])\n",
    "print(model.summary())\n",
    "hist = model.fit_generator(epochs = num_epochs,  # choose how many epochs to train for (watch the loss to see when to stop)\n",
    "                           steps_per_epoch = train_steps,\n",
    "                           generator = TrainGenerator(),  # see above\n",
    "                           use_multiprocessing = True,\n",
    "                           workers = 8)  # use this to split batch processing into multiple CPUs (but don't take over the VM completely!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(hist, cb = None):\n",
    "    epochs = range(1, 100) #1, num_epochs + 1\n",
    "    plt.figure(figsize = (12,8))\n",
    "    plt.subplot(211)\n",
    "    plt.plot(epochs, hist.history[\"acc\"], '.-', color = '#31E080', label = \"Training Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.subplot(212)\n",
    "    plt.plot(epochs, hist.history[\"loss\"], '.-', color = '#31E080', label = \"Training Loss\")\n",
    "    plt.legend()\n",
    "    plt.legend()\n",
    "    plt.savefig(params.figures_path + \"_metrics\", dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = '6col-test-set.bed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestGenerator(Sequence):\n",
    "    def __init__(self):\n",
    "        self.testingfile = test_set\n",
    "        self.converter = PyfaidxCoordsToVals('GRCh38.p13.genome.fa')\n",
    "        self.batchsize = batchsize\n",
    "        self.steps_per_epoch = train_steps\n",
    "        self.total_epochs = num_epochs  # how many epochs to train for (you're using enough epochs when the loss stops going down)\n",
    "        self.get_coords()\n",
    "        self.on_epoch_end()\n",
    "    def __len__(self):  # required by Keras -- returns # of batches to expect\n",
    "        print('running __len__')\n",
    "        return self.steps_per_epoch\n",
    "    def get_coords(self):\n",
    "        print(\"running get_coords\")\n",
    "        with open(self.testingfile) as testf:\n",
    "            #self.labels = [int(line.split()[-6:]) for line in testf]  # assumes last columns in file are the labels, and assumes 6 label columns\n",
    "            #coords_tmp = [line.split()[:3] for line in testf]\n",
    "            #self.coords = [Coordinates(coord[0], int(coord[1]), int(coord[2])) for coord in coords_tmp]\n",
    "            self.coords = []\n",
    "            for line in testf:\n",
    "                temp = line.split()\n",
    "                tempList = [temp[0], int(temp[1]), int(temp[2])]\n",
    "                self.coords.append(Coordinates(tempList[0], tempList[1], tempList[2]))\n",
    "            #should I cast them as numpy arrays?\n",
    "    def __getitem__(self, batch_index):\n",
    "        print(\"running __getitem__\")\n",
    "        # get one-hot encoded sequences, using coordinates, for the next batch\n",
    "        seqs_onehot = self.converter(self.coords[batch_index * self.batchsize : (batch_index + 1) * self.batchsize])\n",
    "        \n",
    "        # sanity checks\n",
    "        assert seqs_onehot.shape[0] == np.array(labels).shape[0], (seqs_onehot.shape[0], np.array(labels).shape[0])\n",
    "        assert seqs_onehot.shape[0] == self.batchsize\n",
    "        return seqs_onehot\n",
    "    def on_epoch_end(self):\n",
    "        # shuffle labels and coordinates (together) between epochs\n",
    "        print(\"running on_epoch_end\")\n",
    "        self.coords = random.shuffle(self.coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist2 = model.fit_generator(epochs = num_epochs,  # choose how many epochs to train for (watch the loss to see when to stop)\n",
    "                           steps_per_epoch = train_steps,\n",
    "                           generator = TestGenerator(),  # see above\n",
    "                           use_multiprocessing = True,\n",
    "                           workers = 8)  # use this to split batch processing into multiple CPUs (but don't take over the VM completely!)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
